{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCQ1pCahGWclOIRy/gVswQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/achpooja/NLP-Elective/blob/main/NLPMay24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SCW-ARspc00",
        "outputId": "6d4cb746-86c6-4127-d4ca-fa04ebad675c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# import nltk\n",
        "# nltk.download('punkt_tab')\n",
        "# nltk.download('stopwords')\n",
        "# nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiVUUZB1pmYP",
        "outputId": "0b8c7498-e1dc-4ba1-deaa-224f4233dfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "print('Number of stop words ', len(stop_words))\n",
        "text = \"I am Shree. I am from here. I study this. I like this. I dislike him. He/She is very nice.\"\n",
        "sentences = nltk.sent_tokenize(text)\n",
        "print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVtCDbAbp36D",
        "outputId": "501d681f-5fb1-441a-970e-2ccfd09bedd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of stop words  198\n",
            "['I am Shree.', 'I am from here.', 'I study this.', 'I like this.', 'I dislike him.', 'He/She is very nice.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    # Lower Case\n",
        "    text = text.lower()\n",
        "    print(\"Lower text\", text)\n",
        "    # Removing Punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    print(\"Puncutation\", text)\n",
        "    # Removing Numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    print(\"Numbers\", text)\n",
        "    # Removing Whitespace\n",
        "    text = text.strip()\n",
        "    print(\"WhiteSpace\", text)\n",
        "    # Sentences Tokenization\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    # print(sentences)\n",
        "    # Word Tokenization and stop words\n",
        "    stop_words = set (stopwords.words('english')) # Use a set for faster lookup\n",
        "\n",
        "    # Word Tokenization and stop words\n",
        "    words = [word for sentence in sentences for word in nltk.word_tokenize(sentence) if word not in stop_words]\n",
        "    return words\n",
        "    # return text\n",
        "processed_words = preprocess_text(text)\n",
        "processed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkXEMCGYp40L",
        "outputId": "ab83c470-c8cf-4a1c-98ed-93a70155b77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower text i am shree. i am from here. i study this. i like this. i dislike him. he/she is very nice.\n",
            "Puncutation i am shree i am from here i study this i like this i dislike him heshe is very nice\n",
            "Numbers i am shree i am from here i study this i like this i dislike him heshe is very nice\n",
            "WhiteSpace i am shree i am from here i study this i like this i dislike him heshe is very nice\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['shree', 'study', 'like', 'dislike', 'heshe', 'nice']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note for Fake News Detection\n",
        "\n",
        "df[title_token]=df[title].apply()\n",
        "\n",
        "inside apply() apply the preprocessing function inside this"
      ],
      "metadata": {
        "id": "cryouPJszOaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3vQaHzsEqCbm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}